# ğŸ“„ Multimodal Document Processing RAG with LangChain

An intelligent **Streamlit-based application** designed for uploading and querying multimodal documents with ease. The system extracts, embeds, stores, and retrieves information from a variety of file formats, powered by **LangChain**, **Milvus**, **Transformers**, **Whisper**, and more.

---

## ğŸš€ What This Project Does

This app provides an end-to-end workflow for processing diverse document types and performing smart searches using **RAG (Retrieval-Augmented Generation)**. Whether itâ€™s audio files, PDFs, or YAML configs â€” this tool helps you extract insights using natural language queries.

---

## âœ¨ Key Features

### ğŸ—‚ï¸ File Upload & Content Extraction

Supports multiple input formats:

- **Textual**: `.txt`, `.pdf`, `.csv`, `.json`, `.yaml`, `.docx`  
- **Media**: `.mp3`, `.wav`, `.mp4`

Extraction handled by:

- ğŸ”Š **Audio**: `Whisper` + `pydub`  
- ğŸ¥ **Video**: Custom parsing pipeline  
- ğŸ“„ **Text/Docs**: LangChain document loaders  

---

### ğŸ§  Smart Storage with Milvus

- Vectorizes content using **HuggingFace Embeddings**  
- Stores vectors in **Milvus** for high-speed similarity search  

---

### ğŸ” AI-Powered Querying

- Ask natural language questions  
- Retrieves relevant data via LangChainâ€™s **RAG mechanism**  
- Returns intelligent, contextual responses  

---

## ğŸ–¥ï¸ Getting Started

### â–¶ï¸ Launch the App

```bash

streamlit run app.py

ğŸ§­ Modes of Operation::

ğŸ“¤ Upload Mode

- Upload any supported file  
- Extract content and store embeddings in **Milvus**  
- View extracted data immediately  

â“ Query Mode

- Enter a natural language question  
- Fetch related chunks from the **vector database**  
- Generate AI-driven answers using **LangChain**

---

ğŸ“ Project Structure

ğŸ“ project-root/
â”œâ”€â”€ app.py                # Main app logic: UI, upload, query
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ audio_utils.py    # Audio chunking & transcription
â”‚   â”œâ”€â”€ video_utils.py    # Video file processing
â”‚   â””â”€â”€ document_utils.py # CSV, JSON, YAML, PDF, etc.
â””â”€â”€ README.md             # Project documentation


ğŸ“Œ Example Workflow

ğŸ”¼ Upload & Store

1. Switch to **Upload Files**  
2. Drop in a file (e.g., `meeting.mp3`)  
3. View extracted content and embedding status  

â“ Ask a Question

1. Go to **Query**  
2. Type in a question like _"What was discussed about project deadlines?"_  
3. Receive a detailed, factual answer using **RAG**

---

ğŸŒ± Future Improvements
 
- ğŸ“ Support more file formats and embedding strategies  
- âš™ï¸ Scale for large corpora and concurrent queries  

---

ğŸ§  Intent Detection

- Determines whether a user query is **chitchat** or requires **vector database search**  
- Helps optimize performance by skipping retrieval for casual or irrelevant questions  
- Routes intent-based queries to LangChainâ€™s **RAG pipeline**, and handles small talk separately  
